\section{Introduction}
Recent advances in end-to-end humanoid control have achieved remarkable agility and expressiveness 
\cite{liao2025beyondmimicmotiontrackingversatile, ji2024exbody2, cheng2024express, zhang2025falcon, li2025amo}.
However, most existing systems are restricted to single-skill policies and lack the ability to generalize across diverse motions or respond to high-level semantic commands.

This project aims to develop a unified, language-conditioned whole-body control policy capable of producing dynamically stable motion trajectories from text prompts. 
The controller is based on a trajectory diffusion model pre-trained on motion datasets with and without language labels, followed by fine-tuning on high-quality, re-targeted humanoid control data.

Our long-term vision is a humanoid platform that can perform a broad range of physically grounded tasks upon natural language instruction, enabling more intuitive humanâ€“robot interaction.